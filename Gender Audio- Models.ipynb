{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML IN BIOMED SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "F1 Score for Original Dataset: 0.8777692895339955\n",
      "Classification Report for Original Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       1.00      0.74      0.85        19\n",
      "        male       0.82      1.00      0.90        23\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.91      0.87      0.88        42\n",
      "weighted avg       0.90      0.88      0.88        42\n",
      "\n",
      "Best Parameters for Original Dataset: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "F1 Score for Denoised Dataset: 0.8306595365418895\n",
      "Classification Report for Denoised Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       0.87      0.72      0.79        18\n",
      "        male       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.84      0.82      0.83        42\n",
      "weighted avg       0.84      0.83      0.83        42\n",
      "\n",
      "Best Parameters for Denoised Dataset: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Function to load data\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Function to process data, train and evaluate model with Grid Search\n",
    "def process_and_evaluate_with_grid_search(data):\n",
    "    # Splitting data into features and target\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Defining the parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20, 30],  # Maximum number of levels in each decision tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of data points placed in a node before the node is split\n",
    "        'min_samples_leaf': [1, 2, 4]  # Minimum number of data points allowed in a leaf node\n",
    "    }\n",
    "    \n",
    "    # Creating the Random Forest Classifier\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Setting up the GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_weighted', verbose=1)\n",
    "    \n",
    "    # Running Grid Search to find the best parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best estimator found by Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Making predictions with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return f1, report, grid_search.best_params_\n",
    "\n",
    "# Load both datasets\n",
    "original_data = load_data('gender_audio_features_Final_greeshma.csv')\n",
    "denoised_data = load_data('gender_audio_features_denoised_greeshma.csv')\n",
    "\n",
    "# Evaluate the original dataset\n",
    "f1_original, report_original, best_params_original = process_and_evaluate_with_grid_search(original_data)\n",
    "print(\"F1 Score for Original Dataset:\", f1_original)\n",
    "print(\"Classification Report for Original Dataset:\\n\", report_original)\n",
    "print(\"Best Parameters for Original Dataset:\", best_params_original)\n",
    "\n",
    "# Evaluate the denoised dataset\n",
    "f1_denoised, report_denoised, best_params_denoised = process_and_evaluate_with_grid_search(denoised_data)\n",
    "print(\"F1 Score for Denoised Dataset:\", f1_denoised)\n",
    "print(\"Classification Report for Denoised Dataset:\\n\", report_denoised)\n",
    "print(\"Best Parameters for Denoised Dataset:\", best_params_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "F1 Score for Original Dataset: 0.8571428571428571\n",
      "Classification Report for Original Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       0.78      0.95      0.86        19\n",
      "        male       0.95      0.78      0.86        23\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.86      0.86      0.86        42\n",
      "weighted avg       0.87      0.86      0.86        42\n",
      "\n",
      "Best Parameters for Original Dataset: {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "F1 Score for Denoised Dataset: 0.7868131868131869\n",
      "Classification Report for Denoised Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       0.71      0.83      0.77        18\n",
      "        male       0.86      0.75      0.80        24\n",
      "\n",
      "    accuracy                           0.79        42\n",
      "   macro avg       0.79      0.79      0.78        42\n",
      "weighted avg       0.80      0.79      0.79        42\n",
      "\n",
      "Best Parameters for Denoised Dataset: {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Function to load data\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Function to process data, train and evaluate model with Grid Search\n",
    "def process_and_evaluate_with_grid_search(data):\n",
    "    # Splitting data into features and target\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Defining the parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']  # Type of the kernel\n",
    "    }\n",
    "    \n",
    "    # Creating the SVM Classifier\n",
    "    model = SVC(random_state=42)\n",
    "    \n",
    "    # Setting up the GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_weighted', verbose=1)\n",
    "    \n",
    "    # Running Grid Search to find the best parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best estimator found by Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Making predictions with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return f1, report, grid_search.best_params_\n",
    "\n",
    "# Load both datasets\n",
    "original_data = load_data('gender_audio_features_Final_greeshma.csv')\n",
    "denoised_data = load_data('gender_audio_features_denoised_greeshma.csv')\n",
    "\n",
    "\n",
    "# Evaluate the original dataset\n",
    "f1_original, report_original, best_params_original = process_and_evaluate_with_grid_search(original_data)\n",
    "print(\"F1 Score for Original Dataset:\", f1_original)\n",
    "print(\"Classification Report for Original Dataset:\\n\", report_original)\n",
    "print(\"Best Parameters for Original Dataset:\", best_params_original)\n",
    "\n",
    "# Evaluate the denoised dataset\n",
    "f1_denoised, report_denoised, best_params_denoised = process_and_evaluate_with_grid_search(denoised_data)\n",
    "print(\"F1 Score for Denoised Dataset:\", f1_denoised)\n",
    "print(\"Classification Report for Denoised Dataset:\\n\", report_denoised)\n",
    "print(\"Best Parameters for Denoised Dataset:\", best_params_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "F1 Score for Original Dataset: 0.9196401141101602\n",
      "Classification Report for Original Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       0.88      0.92      0.90        24\n",
      "        male       0.95      0.92      0.93        38\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.91      0.92      0.92        62\n",
      "weighted avg       0.92      0.92      0.92        62\n",
      "\n",
      "Best Parameters for Original Dataset: {'C': 1}\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "F1 Score for Denoised Dataset: 0.9025980819529206\n",
      "Classification Report for Denoised Dataset:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      female       0.92      0.85      0.88        26\n",
      "        male       0.89      0.94      0.92        36\n",
      "\n",
      "    accuracy                           0.90        62\n",
      "   macro avg       0.91      0.90      0.90        62\n",
      "weighted avg       0.90      0.90      0.90        62\n",
      "\n",
      "Best Parameters for Denoised Dataset: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Function to load data\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Function to process data, train and evaluate model with Grid Search\n",
    "def process_and_evaluate_with_grid_search(data):\n",
    "    # Splitting data into features and target\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Defining the parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100]  # Regularization parameter\n",
    "    }\n",
    "    \n",
    "    # Creating the SVM Classifier with a linear kernel\n",
    "    model = SVC(kernel='linear', random_state=42)\n",
    "    \n",
    "    # Setting up the GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_weighted', verbose=1)\n",
    "    \n",
    "    # Running Grid Search to find the best parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best estimator found by Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Making predictions with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return f1, report, grid_search.best_params_\n",
    "\n",
    "# Load data\n",
    "original_data = load_data('gender_audio_features_Final_greeshma.csv')\n",
    "denoised_data = load_data('gender_audio_features_denoised_greeshma.csv')\n",
    "\n",
    "# Evaluate the original dataset\n",
    "f1_original, report_original, best_params_original = process_and_evaluate_with_grid_search(original_data)\n",
    "print(\"F1 Score for Original Dataset:\", f1_original)\n",
    "print(\"Classification Report for Original Dataset:\\n\", report_original)\n",
    "print(\"Best Parameters for Original Dataset:\", best_params_original)\n",
    "\n",
    "# Evaluate the denoised dataset\n",
    "f1_denoised, report_denoised, best_params_denoised = process_and_evaluate_with_grid_search(denoised_data)\n",
    "print(\"F1 Score for Denoised Dataset:\", f1_denoised)\n",
    "print(\"Classification Report for Denoised Dataset:\\n\", report_denoised)\n",
    "print(\"Best Parameters for Denoised Dataset:\", best_params_denoised)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Statistical Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest scores: [1.         1.         1.         0.93265993 0.86666667 0.93265993\n",
      " 1.         1.         0.93265993 0.86111111]\n",
      "SVM scores: [1.         1.         1.         0.93265993 0.93265993 0.86666667\n",
      " 1.         1.         0.93265993 0.93265993]\n",
      "Paired t-test t-statistic: -0.5881821660747185\n",
      "Paired t-test p-value: 0.5708727981947372\n",
      "There is no significant difference between the two models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load a dataset (example using Iris dataset)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Define classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Define cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "rf_scores = cross_val_score(rf_classifier, X, y, cv=cv, scoring='f1_macro')\n",
    "svm_scores = cross_val_score(svm_classifier, X, y, cv=cv, scoring='f1_macro')\n",
    "\n",
    "# Perform paired t-test\n",
    "t_stat, p_value = ttest_rel(rf_scores, svm_scores)\n",
    "\n",
    "print(\"Random Forest scores:\", rf_scores)\n",
    "print(\"SVM scores:\", svm_scores)\n",
    "print(\"Paired t-test t-statistic:\", t_stat)\n",
    "print(\"Paired t-test p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the two models.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the two models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
