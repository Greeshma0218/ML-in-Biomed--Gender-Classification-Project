{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, duration = 140):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(file_path, sr=22050, duration = duration)\n",
    "        \n",
    "        # Extract features\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_fft = 441, hop_length = 220, n_mfcc=13).T, axis=0)  # MFCCs\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)     # Chroma\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)     # Mel Spectrogram\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)  # Spectral Contrast\n",
    "\n",
    "        \n",
    "        return np.hstack([mfccs, chroma, mel, contrast])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_files(base_path, duration = 140):\n",
    "    data = []\n",
    "    for label in ['male', 'female']:  # Assuming folders are named 'male' and 'female'\n",
    "        folder_path = os.path.join(base_path, label)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.ogg'):  # Check for .ogg files\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                features = extract_features(file_path, duration= duration)\n",
    "                if features is not None:\n",
    "                    data.append([*features, label])  # Append features and label\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    columns = [f'mfcc_{i+1}' for i in range(13)] + \\\n",
    "              [f'chroma_{i+1}' for i in range(12)] + \\\n",
    "              [f'mel_{i+1}' for i in range(128)] + \\\n",
    "              [f'contrast_{i+1}' for i in range(7)] + \\\n",
    "              ['label']\n",
    "    return pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing D:\\Audios\\female\\41.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\42.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\43.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio12.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio31.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio34.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio37.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audiof11.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audiof8.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_173.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_192.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_212.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_214.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_263.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_271.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_272.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_48.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Feature extraction completed. Dataset saved to 'gender_audio_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Set the base path\n",
    "base_path = r\"D:\\Audios\"\n",
    "\n",
    "# Extract features and create the dataset\n",
    "audio_data = process_audio_files(base_path)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "audio_data.to_csv('gender_audio_features_Final_greeshma.csv', index=False)\n",
    "\n",
    "print(\"Feature extraction completed. Dataset saved to 'gender_audio_features.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENOISING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Band-Pass Filter function\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return lfilter(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function with filtering\n",
    "def extract_features(file_path, duration=140, lowcut=85.0, highcut=8000.0):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(file_path, sr=22050, duration=duration)\n",
    "        \n",
    "        # Apply band-pass filter\n",
    "        filtered_audio = bandpass_filter(audio, lowcut, highcut, sr)\n",
    "        \n",
    "        # Extract features\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=filtered_audio, sr=sr, n_fft = 441, hop_length = 220, n_mfcc=13).T, axis=0)  # MFCCs\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=filtered_audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)     # Chroma\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=filtered_audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)     # Mel Spectrogram\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(y=filtered_audio, sr=sr, n_fft = 441, hop_length = 220).T, axis=0)  # Spectral Contrast\n",
    "        \n",
    "        return np.hstack([mfccs, chroma, mel, contrast])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all audio files in the dataset\n",
    "def process_audio_files(base_path, duration=140, lowcut=85.0, highcut=8000.0):\n",
    "    data = []\n",
    "    for label in ['male', 'female']:  # Assuming folders are named 'male' and 'female'\n",
    "        folder_path = os.path.join(base_path, label)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.ogg'):  # Check for .ogg files\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                features = extract_features(file_path, duration=duration, lowcut=lowcut, highcut=highcut)\n",
    "                if features is not None:\n",
    "                    data.append([*features, label])  # Append features and label\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    columns = [f'mfcc_{i+1}' for i in range(13)] + \\\n",
    "              [f'chroma_{i+1}' for i in range(12)] + \\\n",
    "              [f'mel_{i+1}' for i in range(128)] + \\\n",
    "              [f'contrast_{i+1}' for i in range(7)] + \\\n",
    "              ['label']\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing D:\\Audios\\female\\41.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\42.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\43.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio12.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio31.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio34.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio37.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audiof11.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audiof8.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_173.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_192.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_212.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_214.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_263.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_271.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_272.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Error processing D:\\Audios\\female\\audio_48.ogg: module 'soundfile' has no attribute 'SoundFileRuntimeError'\n",
      "Feature extraction with denoising completed. Dataset saved to 'gender_audio_features_denoised.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Set the base path\n",
    "base_path = r\"D:\\Audios\"\n",
    "\n",
    "# Extract features and create the dataset\n",
    "audio_data = process_audio_files(base_path, duration=140)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "audio_data.to_csv('gender_audio_features_denoised_greeshma.csv', index=False)\n",
    "\n",
    "print(\"Feature extraction with denoising completed. Dataset saved to 'gender_audio_features_denoised.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Test Results for Original Dataset:\n",
      "        Feature    t-stat       p-value\n",
      "0        mfcc_1 -0.895155  3.718334e-01\n",
      "1        mfcc_2 -3.507170  5.898417e-04\n",
      "2        mfcc_3 -0.221295  8.251007e-01\n",
      "3        mfcc_4 -5.674025  6.050289e-08\n",
      "4        mfcc_5 -5.101659  9.666642e-07\n",
      "..          ...       ...           ...\n",
      "155  contrast_3  5.503707  1.335542e-07\n",
      "156  contrast_4  2.313023  2.192591e-02\n",
      "157  contrast_5  0.460882  6.455465e-01\n",
      "158  contrast_6 -2.169235  3.142753e-02\n",
      "159  contrast_7 -0.821837  4.121347e-01\n",
      "\n",
      "[160 rows x 3 columns]\n",
      "\n",
      "T-Test Results for Denoised Dataset:\n",
      "        Feature    t-stat       p-value\n",
      "0        mfcc_1 -0.810958  4.183983e-01\n",
      "1        mfcc_2 -3.772705  2.303710e-04\n",
      "2        mfcc_3 -0.678700  4.981350e-01\n",
      "3        mfcc_4 -5.153316  7.654924e-07\n",
      "4        mfcc_5 -6.052766  8.900398e-09\n",
      "..          ...       ...           ...\n",
      "155  contrast_3  5.397354  2.212651e-07\n",
      "156  contrast_4  2.246234  2.597780e-02\n",
      "157  contrast_5  0.428838  6.686489e-01\n",
      "158  contrast_6 -2.176035  3.090479e-02\n",
      "159  contrast_7  5.253856  3.789427e-07\n",
      "\n",
      "[160 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the datasets (replace with the correct file paths)\n",
    "original_dataset = pd.read_csv('gender_audio_features_Final_greeshma.csv')  # Path to original dataset\n",
    "denoised_dataset = pd.read_csv('gender_audio_features_denoised_greeshma.csv')  # Path to denoised dataset\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "def preprocess_dataset(dataset):\n",
    "    # Separate features and labels\n",
    "    X = dataset.iloc[:, :-1]  # All columns except the last are features\n",
    "    y = dataset.iloc[:, -1]   # The last column is the label\n",
    "\n",
    "    # Encode labels (if not already encoded)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Convert normalized X back to a DataFrame for easier handling\n",
    "    X = pd.DataFrame(X, columns=dataset.columns[:-1])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Preprocess both datasets\n",
    "X_original, y_original = preprocess_dataset(original_dataset)\n",
    "X_denoised, y_denoised = preprocess_dataset(denoised_dataset)\n",
    "\n",
    "# Function to perform t-tests on features\n",
    "def perform_t_tests(X, y):\n",
    "    # Separate data by class (assuming 0 for Female, 1 for Male)\n",
    "    group_0 = X[y == 0]  # Features for Female\n",
    "    group_1 = X[y == 1]  # Features for Male\n",
    "\n",
    "    # Perform t-test for each feature\n",
    "    t_test_results = []\n",
    "    for feature in range(X.shape[1]):\n",
    "        t_stat, p_value = ttest_ind(group_0.iloc[:, feature], group_1.iloc[:, feature], equal_var=False)\n",
    "        t_test_results.append({'Feature': X.columns[feature], 't-stat': t_stat, 'p-value': p_value})\n",
    "\n",
    "    return pd.DataFrame(t_test_results)\n",
    "\n",
    "# Perform t-tests on both datasets\n",
    "t_test_results_original = perform_t_tests(X_original, y_original)\n",
    "t_test_results_denoised = perform_t_tests(X_denoised, y_denoised)\n",
    "\n",
    "# Save results to CSV for analysis\n",
    "t_test_results_original.to_csv('t_test_results_original.csv', index=False)\n",
    "t_test_results_denoised.to_csv('t_test_results_denoised.csv', index=False)\n",
    "\n",
    "# Print results for quick view\n",
    "print(\"T-Test Results for Original Dataset:\")\n",
    "print(t_test_results_original)\n",
    "\n",
    "print(\"\\nT-Test Results for Denoised Dataset:\")\n",
    "print(t_test_results_denoised)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
